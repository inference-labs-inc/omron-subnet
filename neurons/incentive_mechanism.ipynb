{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Omron's Incentive Mechanism\n",
                "The below demonstration provides an illustration of Omron's incentive mechanism. This incentive mechanism operates within a zero knowledge proof system, allowing validators to trustlessly prove their scoring within the subnet."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import random\n",
                "import logging\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import Dict, List, Tuple\n",
                "import json\n",
                "import bittensor as bt\n",
                "import numpy as np\n",
                "from _validator.scoring.reward import FLATTENING_COEFFICIENT, MAXIMUM_RESPONSE_TIME_DECIMAL, PROOF_SIZE_THRESHOLD, PROOF_SIZE_WEIGHT, RATE_OF_DECAY, RATE_OF_RECOVERY, Reward\n",
                "from deployment_layer.circuit_store import circuit_store\n",
                "\n",
                "from constants import BATCHED_PROOF_OF_WEIGHTS_MODEL_ID, SINGLE_PROOF_OF_WEIGHTS_MODEL_ID\n",
                "from execution_layer.verified_model_session import VerifiedModelSession\n",
                "from execution_layer.circuit import ProofSystem, Circuit\n",
                "from _validator.models.request_type import RequestType\n",
                "from execution_layer.generic_input import GenericInput\n",
                "\n",
                "RESPONSE_TIME_WEIGHT = 0.75\n",
                "MAX_RESPONSE_TIME = 30\n",
                "MIN_RESPONSE_TIME = 0\n",
                "NUM_KEYS_TO_SIMULATE = 256\n",
                "PLOT_INTERVALS = 30\n",
                "MAX_SCORE = 1\n",
                "BATCH_SIZE = 256\n",
                "ENABLE_LOGS = True\n",
                "FIX_TIMES_AFTER_INTERVAL = False\n",
                "FIX_COMPETITION_AFTER_INTERVAL = True\n",
                "USE_JOLT = False\n",
                "CIRCUIT_ONLY = True\n",
                "\n",
                "MODEL_ID = SINGLE_PROOF_OF_WEIGHTS_MODEL_ID if BATCH_SIZE == 256 else BATCHED_PROOF_OF_WEIGHTS_MODEL_ID\n",
                "circuit = Circuit(MODEL_ID)\n",
                "if ENABLE_LOGS:\n",
                "    bt.logging.on()\n",
                "else:\n",
                "    bt.logging.off()\n",
                "    logging.disable(logging.CRITICAL)\n",
                "\n",
                "def log(message: str) -> None:\n",
                "    if ENABLE_LOGS:\n",
                "        print(message)\n",
                "\n",
                "\n",
                "def run_inference_via_proof_system(\n",
                "    batch_inputs: Dict[str, torch.Tensor]\n",
                ") -> torch.Tensor:\n",
                "    if not circuit:\n",
                "        raise ValueError(\"Circuit is not available.\")\n",
                "    if not circuit.settings:\n",
                "        scale = 1\n",
                "    else:\n",
                "        scale = circuit.settings[\"scaling\"]\n",
                "    inputs = {\n",
                "        \"maximum_score\": (batch_inputs[\"maximum_score\"] * scale).int().tolist(),\n",
                "        \"previous_score\": (batch_inputs[\"previous_score\"] * scale).int().tolist(),\n",
                "        \"verified\": batch_inputs[\"verified\"].tolist(),\n",
                "        \"proof_size\": (batch_inputs[\"proof_size\"] * scale).to(torch.uint64).tolist(),\n",
                "        \"response_time\": (batch_inputs[\"response_time\"] * scale).int().tolist(),\n",
                "        \"competition\": (batch_inputs[\"competition\"] * scale).int().tolist(),\n",
                "        \"maximum_response_time\": (batch_inputs[\"maximum_response_time\"] * scale)\n",
                "        .int()\n",
                "        .tolist(),\n",
                "        \"minimum_response_time\": (batch_inputs[\"minimum_response_time\"] * scale)\n",
                "        .int()\n",
                "        .tolist(),\n",
                "        \"block_number\": batch_inputs[\"block_number\"].tolist(),\n",
                "        \"validator_uid\": batch_inputs[\"validator_uid\"].tolist(),\n",
                "        \"miner_uid\": batch_inputs[\"miner_uid\"].tolist(),\n",
                "    }\n",
                "\n",
                "    inputs[\"scaling\"] = scale\n",
                "    inputs[\"RATE_OF_DECAY\"] = int(RATE_OF_DECAY * scale)\n",
                "    inputs[\"RATE_OF_RECOVERY\"] = int(RATE_OF_RECOVERY * scale)\n",
                "    inputs[\"FLATTENING_COEFFICIENT\"] = int(FLATTENING_COEFFICIENT * scale)\n",
                "    inputs[\"PROOF_SIZE_WEIGHT\"] = int(PROOF_SIZE_WEIGHT * scale)\n",
                "    inputs[\"PROOF_SIZE_THRESHOLD\"] = int(PROOF_SIZE_THRESHOLD * scale)\n",
                "    inputs[\"RESPONSE_TIME_WEIGHT\"] = int(RESPONSE_TIME_WEIGHT * scale)\n",
                "    inputs[\"MAXIMUM_RESPONSE_TIME_DECIMAL\"] = int(\n",
                "        MAXIMUM_RESPONSE_TIME_DECIMAL * scale\n",
                "    )\n",
                "    inputs[\"COMPETITION_WEIGHT\"] = int(0.25 * scale)\n",
                "\n",
                "    session = VerifiedModelSession(GenericInput(RequestType.RWR, inputs), circuit)\n",
                "    scores = None\n",
                "    if circuit.proof_system == ProofSystem.CIRCOM:\n",
                "        witness_content = session.generate_witness(return_content=True)\n",
                "        scores = torch.tensor([float(x) for x in (witness_content[1 : BATCH_SIZE + 1])])\n",
                "    elif circuit.proof_system == ProofSystem.JOLT:\n",
                "        proof, public_data, time = session.gen_proof()\n",
                "        json_data = json.loads(public_data)\n",
                "        scores = torch.tensor([float(x) for x in (json_data)])\n",
                "\n",
                "    return scores / scale\n",
                "\n",
                "def generate_sample_inputs() -> Dict[str, torch.Tensor]:\n",
                "    inputs = {\n",
                "        \"maximum_score\": torch.full((BATCH_SIZE,), MAX_SCORE, dtype=torch.float32),\n",
                "        \"previous_score\": torch.tensor(\n",
                "            [random.uniform(0, MAX_SCORE) for _ in range(BATCH_SIZE)],\n",
                "            dtype=torch.float32,\n",
                "        ),\n",
                "        \"verified\": torch.tensor(\n",
                "            [i != BATCH_SIZE - 1 for i in range(BATCH_SIZE)], dtype=torch.bool\n",
                "        ),\n",
                "        \"proof_size\": torch.tensor(\n",
                "            [random.randint(0, 10000) for _ in range(BATCH_SIZE)], dtype=torch.uint64\n",
                "        ),\n",
                "        \"response_time\": torch.tensor(\n",
                "            [\n",
                "                2\n",
                "                for _ in range(BATCH_SIZE)\n",
                "            ],\n",
                "            dtype=torch.float32,\n",
                "        ),\n",
                "        \"competition\": torch.tensor(\n",
                "            [1.0 for _ in range(BATCH_SIZE)], dtype=torch.float32\n",
                "        ),\n",
                "        \"maximum_response_time\": torch.full(\n",
                "            (BATCH_SIZE,), MAX_RESPONSE_TIME, dtype=torch.float32\n",
                "        ),\n",
                "        \"minimum_response_time\": torch.full(\n",
                "            (BATCH_SIZE,), MIN_RESPONSE_TIME, dtype=torch.float32\n",
                "        ),\n",
                "        \"block_number\": torch.tensor(\n",
                "            [random.randint(3000000, 10000000) for _ in range(BATCH_SIZE)],\n",
                "            dtype=torch.uint64\n",
                "        ),\n",
                "        \"validator_uid\": torch.tensor(\n",
                "            [random.randint(0, 256) for _ in range(BATCH_SIZE)], dtype=torch.uint16\n",
                "        ),\n",
                "        \"miner_uid\": torch.tensor(\n",
                "            [random.randint(0, 256) for _ in range(BATCH_SIZE)], dtype=torch.uint16\n",
                "        ),\n",
                "    }\n",
                "    log(\n",
                "        f\"Generated sample inputs. Shape of 'maximum_score': {inputs['maximum_score'].shape}\"\n",
                "    )\n",
                "    return inputs\n",
                "\n",
                "\n",
                "def run_iterations(\n",
                "    num_iterations: int, initial_inputs: Dict[str, torch.Tensor]\n",
                ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
                "    sample_inputs = initial_inputs.copy()\n",
                "    original_response_times = sample_inputs[\"response_time\"].clone()\n",
                "    original_verified = sample_inputs[\"verified\"].clone()\n",
                "\n",
                "    scores_pow = [sample_inputs[\"previous_score\"].clone()]\n",
                "    scores_torch = [sample_inputs[\"previous_score\"].clone()]\n",
                "    reward_model = Reward()\n",
                "\n",
                "    for i in range(num_iterations):\n",
                "        log(f\"Running iteration {i+1}/{num_iterations}\")\n",
                "        if FIX_TIMES_AFTER_INTERVAL:\n",
                "            if i == num_iterations // 3:\n",
                "                sample_inputs[\"response_time\"] = torch.where(\n",
                "                    torch.arange(BATCH_SIZE) == 0,\n",
                "                    torch.full((BATCH_SIZE,), 1.0),\n",
                "                    torch.where(\n",
                "                        torch.arange(BATCH_SIZE) < BATCH_SIZE // 2,\n",
                "                        torch.full((BATCH_SIZE,), 4.0),\n",
                "                        torch.full((BATCH_SIZE,), 10.0)\n",
                "                    )\n",
                "                )\n",
                "        if FIX_COMPETITION_AFTER_INTERVAL:\n",
                "            if i == num_iterations // 3:\n",
                "                sample_inputs[\"competition\"] = torch.where(\n",
                "                    torch.arange(BATCH_SIZE) == 0,\n",
                "                    torch.full((BATCH_SIZE,), 0.9),\n",
                "                    torch.where(\n",
                "                        torch.arange(BATCH_SIZE) < BATCH_SIZE // 2,\n",
                "                        torch.full((BATCH_SIZE,), 0.0),\n",
                "                        torch.full((BATCH_SIZE,), 0.2)\n",
                "                    )\n",
                "                )\n",
                "\n",
                "        new_scores_pow = run_inference_via_proof_system(sample_inputs)\n",
                "        if not CIRCUIT_ONLY:\n",
                "            new_scores_torch = reward_model(**sample_inputs)[0]\n",
                "            scores_torch.append(new_scores_torch)\n",
                "\n",
                "        scores_pow.append(new_scores_pow)\n",
                "\n",
                "        sample_inputs[\"previous_score\"] = new_scores_pow.clone()\n",
                "        log(\n",
                "            f\"Updated previous_score for next iteration: {sample_inputs['previous_score'][:5]}...\"\n",
                "        )\n",
                "\n",
                "    log(\n",
                "        f\"Completed {num_iterations} iterations. Final scores shape: {scores_pow[-1].shape}\"\n",
                "    )\n",
                "    return (\n",
                "        torch.stack(scores_pow),\n",
                "        torch.stack(scores_torch) if not CIRCUIT_ONLY else None,\n",
                "        original_response_times,\n",
                "        original_verified,\n",
                "        sample_inputs[\"competition\"].clone(),\n",
                "    )\n",
                "\n",
                "\n",
                "def plot_scores_over_time(\n",
                "    scores_over_time_pow: torch.Tensor,\n",
                "    scores_over_time_torch: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                ") -> None:\n",
                "    if CIRCUIT_ONLY:\n",
                "        fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n",
                "    else:\n",
                "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
                "\n",
                "    norm = plt.Normalize(vmin=MIN_RESPONSE_TIME, vmax=MAX_RESPONSE_TIME)\n",
                "    cmap = plt.get_cmap(\"plasma\")\n",
                "    intervention_point = PLOT_INTERVALS // 3\n",
                "\n",
                "    for i in range(BATCH_SIZE):\n",
                "        if FIX_TIMES_AFTER_INTERVAL:\n",
                "            # Plot before intervention\n",
                "            color_before = cmap(norm(response_times[i].item()))\n",
                "            ax1.plot(\n",
                "                range(intervention_point + 1),\n",
                "                scores_over_time_pow[: intervention_point + 1, i],\n",
                "                color=color_before,\n",
                "                alpha=0.5,\n",
                "            )\n",
                "\n",
                "            # Calculate new color based on fixed times\n",
                "            if i == 0:\n",
                "                new_time = 1.0\n",
                "            elif i < BATCH_SIZE // 2:\n",
                "                new_time = 4.0\n",
                "            else:\n",
                "                new_time = 10.0\n",
                "            color_after = cmap(norm(new_time))\n",
                "\n",
                "            # Plot after intervention\n",
                "            ax1.plot(\n",
                "                range(intervention_point, PLOT_INTERVALS + 1),\n",
                "                scores_over_time_pow[intervention_point:, i],\n",
                "                color=color_after,\n",
                "                alpha=0.5,\n",
                "            )\n",
                "        else:\n",
                "            color = cmap(norm(response_times[i].item()))\n",
                "            ax1.plot(\n",
                "                range(PLOT_INTERVALS + 1),\n",
                "                scores_over_time_pow[:, i],\n",
                "                color=color,\n",
                "                alpha=0.5,\n",
                "            )\n",
                "\n",
                "    if FIX_TIMES_AFTER_INTERVAL:\n",
                "        ax1.axvline(\n",
                "            x=intervention_point,\n",
                "            color=\"r\",\n",
                "            linestyle=\"--\",\n",
                "            alpha=0.5,\n",
                "            label=\"Time Fix Point\",\n",
                "        )\n",
                "\n",
                "    sm1 = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
                "    sm1.set_array([])\n",
                "    fig.colorbar(sm1, ax=ax1, label=\"Response Time\")\n",
                "    ax1.set_xlabel(\"Iteration\")\n",
                "    ax1.set_ylabel(\"Score\")\n",
                "    ax1.set_title(\"Change in Scores Over Iterations (PoW)\")\n",
                "    ax1.legend()\n",
                "\n",
                "    if not CIRCUIT_ONLY:\n",
                "        for i in range(BATCH_SIZE):\n",
                "            if FIX_TIMES_AFTER_INTERVAL:\n",
                "                # Plot before intervention\n",
                "                color_before = cmap(norm(response_times[i].item()))\n",
                "                ax2.plot(\n",
                "                    range(intervention_point + 1),\n",
                "                    scores_over_time_torch[: intervention_point + 1, i],\n",
                "                    color=color_before,\n",
                "                    alpha=0.5,\n",
                "                )\n",
                "\n",
                "                # Calculate new color based on fixed times\n",
                "                if i == 0:\n",
                "                    new_time = 1.0\n",
                "                elif i < BATCH_SIZE // 2:\n",
                "                    new_time = 4.0\n",
                "                else:\n",
                "                    new_time = 10.0\n",
                "                color_after = cmap(norm(new_time))\n",
                "\n",
                "                # Plot after intervention\n",
                "                ax2.plot(\n",
                "                    range(intervention_point, PLOT_INTERVALS + 1),\n",
                "                    scores_over_time_torch[intervention_point:, i],\n",
                "                    color=color_after,\n",
                "                    alpha=0.5,\n",
                "                )\n",
                "            else:\n",
                "                color = cmap(norm(response_times[i].item()))\n",
                "                ax2.plot(\n",
                "                    range(PLOT_INTERVALS + 1),\n",
                "                    scores_over_time_torch[:, i],\n",
                "                    color=color,\n",
                "                    alpha=0.5,\n",
                "                )\n",
                "\n",
                "        if FIX_TIMES_AFTER_INTERVAL:\n",
                "            ax2.axvline(\n",
                "                x=intervention_point,\n",
                "                color=\"r\",\n",
                "                linestyle=\"--\",\n",
                "                alpha=0.5,\n",
                "                label=\"Time Fix Point\",\n",
                "            )\n",
                "\n",
                "        sm2 = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
                "        sm2.set_array([])\n",
                "        fig.colorbar(sm2, ax=ax2, label=\"Response Time\")\n",
                "        ax2.set_xlabel(\"Iteration\")\n",
                "        ax2.set_ylabel(\"Score\")\n",
                "        ax2.set_title(\"Change in Scores Over Iterations (Torch)\")\n",
                "        ax2.legend()\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def plot_scores_vs_response_times_with_loss(\n",
                "    final_scores_pow: torch.Tensor,\n",
                "    final_scores_torch: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                "    verified: torch.Tensor,\n",
                "    loss: torch.Tensor,\n",
                ") -> None:\n",
                "    if CIRCUIT_ONLY:\n",
                "        fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n",
                "    else:\n",
                "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6))\n",
                "\n",
                "    sorted_indices = torch.argsort(response_times, descending=True)\n",
                "    sorted_response_times = response_times[sorted_indices]\n",
                "    sorted_scores_pow = final_scores_pow[sorted_indices]\n",
                "    sorted_verified = verified[sorted_indices]\n",
                "\n",
                "    scatter_pow = ax1.scatter(\n",
                "        sorted_response_times[sorted_verified],\n",
                "        sorted_scores_pow[sorted_verified],\n",
                "        c=sorted_response_times[sorted_verified],\n",
                "        cmap=\"plasma\",\n",
                "        label=\"Verified (PoW)\",\n",
                "    )\n",
                "    ax1.scatter(\n",
                "        sorted_response_times[~sorted_verified],\n",
                "        sorted_scores_pow[~sorted_verified],\n",
                "        c=\"red\",\n",
                "        label=\"Non-Verified (PoW)\",\n",
                "    )\n",
                "    fig.colorbar(scatter_pow, ax=ax1, label=\"Response Time\")\n",
                "    ax1.set_xlabel(\"Response Time\")\n",
                "    ax1.set_ylabel(\"Final Score\")\n",
                "    ax1.set_title(\"Final Scores vs Response Times (PoW)\")\n",
                "    ax1.legend()\n",
                "    ax1.invert_xaxis()\n",
                "\n",
                "    if not CIRCUIT_ONLY:\n",
                "        sorted_scores_torch = final_scores_torch[sorted_indices]\n",
                "        scatter_torch = ax2.scatter(\n",
                "            sorted_response_times[sorted_verified],\n",
                "            sorted_scores_torch[sorted_verified],\n",
                "            c=sorted_response_times[sorted_verified],\n",
                "            cmap=\"plasma\",\n",
                "            label=\"Verified (Torch)\",\n",
                "        )\n",
                "        ax2.scatter(\n",
                "            sorted_response_times[~sorted_verified],\n",
                "            sorted_scores_torch[~sorted_verified],\n",
                "            c=\"red\",\n",
                "            label=\"Non-Verified (Torch)\",\n",
                "        )\n",
                "        fig.colorbar(scatter_torch, ax=ax2, label=\"Response Time\")\n",
                "        ax2.set_xlabel(\"Response Time\")\n",
                "        ax2.set_ylabel(\"Final Score\")\n",
                "        ax2.set_title(\"Final Scores vs Response Times (Torch)\")\n",
                "        ax2.legend()\n",
                "        ax2.invert_xaxis()\n",
                "\n",
                "        ax3.plot(range(len(loss)), loss.numpy())\n",
                "        ax3.set_xlabel(\"Iteration\")\n",
                "        ax3.set_ylabel(\"Mean Squared Error\")\n",
                "        ax3.set_title(\"Loss between Torch and PoW\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "    log(f\"PoW - Sorted final scores sample: {sorted_scores_pow[:5]}...\")\n",
                "    log(f\"PoW - Sorted response times sample: {sorted_response_times[:5]}...\")\n",
                "    log(f\"PoW - Sorted verified status sample: {sorted_verified[:5]}...\")\n",
                "    if not CIRCUIT_ONLY:\n",
                "        log(f\"Torch - Sorted final scores sample: {sorted_scores_torch[:5]}...\")\n",
                "        log(f\"Torch - Sorted response times sample: {sorted_response_times[:5]}...\")\n",
                "        log(f\"Torch - Sorted verified status sample: {sorted_verified[:5]}...\")\n",
                "\n",
                "\n",
                "def process_weights(\n",
                "    scores: torch.Tensor, uids: torch.Tensor, netuid: int, subtensor: bt.subtensor\n",
                ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
                "    scores_numpy = scores.numpy()\n",
                "    uids_numpy = uids.numpy()\n",
                "    processed_uids, processed_weights = bt.utils.weight_utils.process_weights_for_netuid(\n",
                "        uids=uids_numpy, weights=scores_numpy, netuid=netuid, subtensor=subtensor\n",
                "    )\n",
                "    return torch.tensor(processed_uids), torch.tensor(processed_weights)\n",
                "\n",
                "\n",
                "def plot_processed_weights(\n",
                "    processed_uids: torch.Tensor,\n",
                "    processed_weights: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                "    verified: torch.Tensor,\n",
                "    title: str,\n",
                ") -> None:\n",
                "    sorted_indices = torch.argsort(response_times, descending=True)\n",
                "    sorted_uids = processed_uids[sorted_indices]\n",
                "    sorted_weights = processed_weights[sorted_indices]\n",
                "    sorted_response_times = response_times[sorted_indices]\n",
                "    sorted_verified = verified[sorted_indices]\n",
                "\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    scatter = plt.scatter(\n",
                "        sorted_response_times.numpy(),\n",
                "        sorted_weights.numpy(),\n",
                "        c=sorted_response_times.numpy(),\n",
                "        cmap=\"plasma\",\n",
                "        s=50,\n",
                "        alpha=0.7,\n",
                "    )\n",
                "\n",
                "    plt.scatter(\n",
                "        sorted_response_times[~sorted_verified].numpy(),\n",
                "        sorted_weights[~sorted_verified].numpy(),\n",
                "        facecolors=\"none\",\n",
                "        edgecolors=\"red\",\n",
                "        s=100,\n",
                "        linewidths=2,\n",
                "    )\n",
                "\n",
                "    plt.colorbar(scatter, label=\"Response Time\")\n",
                "    plt.xlabel(\"Response Time\")\n",
                "    plt.ylabel(\"Processed Weight\")\n",
                "    plt.title(title)\n",
                "    plt.gca().invert_xaxis()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def plot_processed_weights_grid(\n",
                "    processed_uids: torch.Tensor,\n",
                "    processed_weights: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                "    verified: torch.Tensor,\n",
                "    title: str,\n",
                ") -> None:\n",
                "    num_charts = BATCH_SIZE // 256\n",
                "    rows = int(np.ceil(np.sqrt(num_charts)))\n",
                "    cols = int(np.ceil(num_charts / rows))\n",
                "\n",
                "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
                "    fig.suptitle(title, fontsize=16)\n",
                "\n",
                "    for i in range(num_charts):\n",
                "        ax = axes[i // cols, i % cols] if num_charts > 1 else axes\n",
                "        start_idx = i * 256\n",
                "        end_idx = (i + 1) * 256\n",
                "\n",
                "        chunk_uids = processed_uids[start_idx:end_idx]\n",
                "        chunk_weights = processed_weights[start_idx:end_idx]\n",
                "        chunk_response_times = response_times[start_idx:end_idx]\n",
                "        chunk_verified = verified[start_idx:end_idx]\n",
                "        sorted_indices = torch.argsort(chunk_response_times, descending=True)\n",
                "        sorted_uids = chunk_uids[sorted_indices]\n",
                "        sorted_weights = chunk_weights[sorted_indices]\n",
                "        sorted_response_times = chunk_response_times[sorted_indices]\n",
                "        sorted_verified = chunk_verified[sorted_indices]\n",
                "\n",
                "        scatter = ax.scatter(\n",
                "            sorted_response_times.numpy(),\n",
                "            sorted_weights.numpy(),\n",
                "            c=sorted_response_times.numpy(),\n",
                "            cmap=\"plasma\",\n",
                "            s=20,\n",
                "            alpha=0.7,\n",
                "        )\n",
                "\n",
                "        ax.scatter(\n",
                "            sorted_response_times[~sorted_verified].numpy(),\n",
                "            sorted_weights[~sorted_verified].numpy(),\n",
                "            facecolors=\"none\",\n",
                "            edgecolors=\"red\",\n",
                "            s=40,\n",
                "            linewidths=1,\n",
                "        )\n",
                "\n",
                "        ax.set_xlabel(\"Response Time\")\n",
                "        ax.set_ylabel(\"Processed Weight\")\n",
                "        ax.set_title(f\"Chunk {i+1}\")\n",
                "\n",
                "        ax.invert_xaxis()\n",
                "\n",
                "    for i in range(num_charts, rows * cols):\n",
                "        fig.delaxes(axes.flatten()[i])\n",
                "\n",
                "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def main() -> None:\n",
                "    initial_inputs = generate_sample_inputs()\n",
                "    scores_over_time_pow, scores_over_time_torch, response_times, verified, competition = (\n",
                "        run_iterations(PLOT_INTERVALS, initial_inputs)\n",
                "    )\n",
                "    plot_scores_over_time(scores_over_time_pow, scores_over_time_torch, response_times)\n",
                "\n",
                "    if not CIRCUIT_ONLY:\n",
                "        loss = torch.mean((scores_over_time_torch - scores_over_time_pow) ** 2, dim=1)\n",
                "    else:\n",
                "        loss = None\n",
                "\n",
                "    final_scores_pow = scores_over_time_pow[-1]\n",
                "    final_scores_torch = scores_over_time_torch[-1] if not CIRCUIT_ONLY else None\n",
                "\n",
                "    sorted_indices = torch.argsort(response_times, descending=True)\n",
                "    sorted_final_scores_pow = final_scores_pow[sorted_indices]\n",
                "    sorted_final_scores_torch = final_scores_torch[sorted_indices] if not CIRCUIT_ONLY else None\n",
                "    sorted_response_times = response_times[sorted_indices]\n",
                "    sorted_competition = competition[sorted_indices]\n",
                "    sorted_verified = verified[sorted_indices]\n",
                "\n",
                "    plot_scores_vs_response_times_with_loss(\n",
                "        sorted_final_scores_pow,\n",
                "        sorted_final_scores_torch,\n",
                "        sorted_competition,\n",
                "        sorted_response_times,\n",
                "        loss if not CIRCUIT_ONLY else torch.zeros(PLOT_INTERVALS),\n",
                "    )\n",
                "\n",
                "    uids = torch.arange(len(final_scores_pow))\n",
                "    netuid = 2\n",
                "    subtensor = bt.subtensor()\n",
                "    processed_uids_pow, processed_weights_pow = process_weights(\n",
                "        final_scores_pow, uids, netuid, subtensor\n",
                "    )\n",
                "    plot_processed_weights(\n",
                "        processed_uids_pow,\n",
                "        processed_weights_pow,\n",
                "        response_times,\n",
                "        verified,\n",
                "        \"Processed Weights (PoW)\",\n",
                "    )\n",
                "    plot_processed_weights_grid(\n",
                "        processed_uids_pow,\n",
                "        processed_weights_pow,\n",
                "        response_times,\n",
                "        verified,\n",
                "        \"Processed Weights Grid (PoW)\",\n",
                "    )\n",
                "\n",
                "    if not CIRCUIT_ONLY:\n",
                "        processed_uids_torch, processed_weights_torch = process_weights(\n",
                "            final_scores_torch, uids, netuid, subtensor\n",
                "        )\n",
                "        plot_processed_weights(\n",
                "            processed_uids_torch,\n",
                "            processed_weights_torch,\n",
                "            response_times,\n",
                "            verified,\n",
                "            \"Processed Weights (Torch)\",\n",
                "        )\n",
                "        plot_processed_weights_grid(\n",
                "            processed_uids_torch,\n",
                "            processed_weights_torch,\n",
                "            response_times,\n",
                "            verified,\n",
                "            \"Processed Weights Grid (Torch)\",\n",
                "        )\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
