{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1 - Querying top miner UID"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import bittensor as bt\n",
                "\n",
                "USE_TESTNET = False\n",
                "\n",
                "if USE_TESTNET:\n",
                "    metagraph = bt.metagraph(netuid=118, network=\"test\")\n",
                "else:\n",
                "    metagraph = bt.metagraph(netuid=2, network=\"finney\")\n",
                "\n",
                "top_miner_uid = int(metagraph.incentive.argmax())\n",
                "print(top_miner_uid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2 - Demonstration of Rewards"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Proof of Weights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import random\n",
                "import logging\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import Dict, List, Tuple\n",
                "import json\n",
                "import bittensor as bt\n",
                "import numpy as np\n",
                "from _validator.scoring.reward import FLATTENING_COEFFICIENT, MAXIMUM_RESPONSE_TIME_DECIMAL, PROOF_SIZE_THRESHOLD, PROOF_SIZE_WEIGHT, RATE_OF_DECAY, RATE_OF_RECOVERY, RESPONSE_TIME_WEIGHT, Reward\n",
                "from deployment_layer.circuit_store import circuit_store\n",
                "\n",
                "from constants import BATCHED_PROOF_OF_WEIGHTS_MODEL_ID, SINGLE_PROOF_OF_WEIGHTS_MODEL_ID, SINGLE_PROOF_OF_WEIGHTS_MODEL_ID_JOLT\n",
                "from execution_layer.verified_model_session import VerifiedModelSession\n",
                "from execution_layer.circuit import ProofSystem\n",
                "\n",
                "MAX_RESPONSE_TIME = 30\n",
                "MIN_RESPONSE_TIME = 0\n",
                "NUM_KEYS_TO_SIMULATE = 256\n",
                "PLOT_INTERVALS = 25\n",
                "MAX_SCORE = 1 / 256\n",
                "BATCH_SIZE = 256\n",
                "ENABLE_LOGS = True\n",
                "FIX_TIMES_AFTER_INTERVAL = False\n",
                "USE_JOLT = True\n",
                "\n",
                "MODEL_ID = SINGLE_PROOF_OF_WEIGHTS_MODEL_ID if BATCH_SIZE == 256 else BATCHED_PROOF_OF_WEIGHTS_MODEL_ID\n",
                "\n",
                "if USE_JOLT and BATCH_SIZE == 256:\n",
                "    MODEL_ID = SINGLE_PROOF_OF_WEIGHTS_MODEL_ID_JOLT\n",
                "elif USE_JOLT:\n",
                "    raise ValueError(\"Jolt is only supported for batch size 256\")\n",
                "\n",
                "circuit = circuit_store.get_circuit(MODEL_ID)\n",
                "\n",
                "if ENABLE_LOGS:\n",
                "    bt.logging.on()\n",
                "else:\n",
                "    bt.logging.off()\n",
                "    logging.disable(logging.CRITICAL)\n",
                "\n",
                "def log(message: str) -> None:\n",
                "    if ENABLE_LOGS:\n",
                "        print(message)\n",
                "\n",
                "\n",
                "def run_inference_via_proof_system(\n",
                "    batch_inputs: Dict[str, torch.Tensor]\n",
                ") -> torch.Tensor:\n",
                "    if not circuit:\n",
                "        raise ValueError(\"Circuit is not available.\")\n",
                "    if not circuit.settings:\n",
<<<<<<< HEAD
                "        raise ValueError(\"Circuit settings are not available.\")\n",
                "    scale = circuit.settings[\"scaling\"]\n",
                "\n",
                "    modified_inputs = {\n",
                "        \"RATE_OF_DECAY\": int(RATE_OF_DECAY * scale),\n",
                "        \"RATE_OF_RECOVERY\": int(RATE_OF_RECOVERY * scale),\n",
                "        \"FLATTENING_COEFFICIENT\": int(FLATTENING_COEFFICIENT * scale),\n",
                "        \"PROOF_SIZE_WEIGHT\": int(PROOF_SIZE_WEIGHT * scale),\n",
                "        \"PROOF_SIZE_THRESHOLD\": int(PROOF_SIZE_THRESHOLD * scale),\n",
                "        \"RESPONSE_TIME_WEIGHT\": int(RESPONSE_TIME_WEIGHT * scale),\n",
                "        \"ACCURACY_WEIGHT\": int(ACCURACY_WEIGHT * scale),\n",
                "        \"MAXIMUM_RESPONSE_TIME_DECIMAL\": int(MAXIMUM_RESPONSE_TIME_DECIMAL * scale),\n",
                "\n",
=======
                "        scale = 1\n",
                "    else:\n",
                "        scale = circuit.settings[\"scaling\"]\n",
                "    inputs = {\n",
>>>>>>> f89a076334b7df3b8f410937696e28ac51b54784
                "        \"maximum_score\": (batch_inputs[\"maximum_score\"] * scale).int().tolist(),\n",
                "        \"previous_score\": (batch_inputs[\"previous_score\"] * scale).int().tolist(),\n",
                "        \"verified\": batch_inputs[\"verified\"].tolist(),\n",
                "        \"proof_size\": (batch_inputs[\"proof_size\"] * scale).to(torch.uint64).tolist(),\n",
                "        \"response_time\": (batch_inputs[\"response_time\"] * scale).int().tolist(),\n",
                "        \"maximum_response_time\": (batch_inputs[\"maximum_response_time\"] * scale)\n",
                "        .int()\n",
                "        .tolist(),\n",
                "        \"minimum_response_time\": (batch_inputs[\"minimum_response_time\"] * scale)\n",
                "        .int()\n",
                "        .tolist(),\n",
                "        \"block_number\": batch_inputs[\"block_number\"].tolist(),\n",
                "        \"validator_uid\": batch_inputs[\"validator_uid\"].tolist(),\n",
                "        \"miner_uid\": batch_inputs[\"miner_uid\"].tolist(),\n",
                "    }\n",
                "\n",
                "    if circuit.proof_system == ProofSystem.CIRCOM:\n",
                "        inputs[\"scaling\"] = scale\n",
                "        inputs[\"RATE_OF_DECAY\"] = int(RATE_OF_DECAY * scale)\n",
                "        inputs[\"RATE_OF_RECOVERY\"] = int(RATE_OF_RECOVERY * scale)\n",
                "        inputs[\"FLATTENING_COEFFICIENT\"] = int(FLATTENING_COEFFICIENT * scale)\n",
                "        inputs[\"PROOF_SIZE_WEIGHT\"] = int(PROOF_SIZE_WEIGHT * scale)\n",
                "        inputs[\"PROOF_SIZE_THRESHOLD\"] = int(PROOF_SIZE_THRESHOLD * scale)\n",
                "        inputs[\"RESPONSE_TIME_WEIGHT\"] = int(RESPONSE_TIME_WEIGHT * scale)\n",
                "        inputs[\"MAXIMUM_RESPONSE_TIME_DECIMAL\"] = int(\n",
                "            MAXIMUM_RESPONSE_TIME_DECIMAL * scale\n",
                "        )\n",
                "    if circuit.proof_system == ProofSystem.JOLT:\n",
                "        inputs = {\n",
                "            \"maximum_score\": (batch_inputs[\"maximum_score\"]).float().tolist(),\n",
                "            \"previous_score\": (batch_inputs[\"previous_score\"]).float().tolist(),\n",
                "            \"verified\": batch_inputs[\"verified\"].tolist(),\n",
                "            \"proof_size\": (batch_inputs[\"proof_size\"]).float().tolist(),\n",
                "            \"response_time\": (batch_inputs[\"response_time\"]).float().tolist(),\n",
                "            \"maximum_response_time\": (batch_inputs[\"maximum_response_time\"])\n",
                "            .float()\n",
                "            .tolist(),\n",
                "            \"minimum_response_time\": (batch_inputs[\"minimum_response_time\"])\n",
                "            .float()\n",
                "            .tolist(),\n",
                "            \"block_number\": batch_inputs[\"block_number\"].tolist(),\n",
                "            \"validator_uid\": batch_inputs[\"validator_uid\"].tolist(),\n",
                "            \"miner_uid\": batch_inputs[\"miner_uid\"].tolist(),\n",
                "            \"uid_responsible_for_proof\": batch_inputs[\"validator_uid\"][-1].item()\n",
                "        }\n",
                "\n",
                "    session = VerifiedModelSession(inputs, circuit)\n",
                "    scores = None\n",
                "    if circuit.proof_system == ProofSystem.CIRCOM:\n",
                "        witness_content = session.generate_witness(return_content=True)\n",
                "        scores = torch.tensor([float(x) for x in (witness_content[1 : BATCH_SIZE + 1])])\n",
                "    elif circuit.proof_system == ProofSystem.JOLT:\n",
                "        proof, public_data, time = session.gen_proof()\n",
                "        json_data = json.loads(public_data)\n",
                "        scores = torch.tensor([float(x) for x in (json_data)])\n",
                "\n",
                "    return scores / scale\n",
                "\n",
                "def generate_sample_inputs() -> Dict[str, torch.Tensor]:\n",
                "    inputs = {\n",
                "        \"maximum_score\": torch.full((BATCH_SIZE,), MAX_SCORE, dtype=torch.float32),\n",
                "        \"previous_score\": torch.tensor(\n",
                "            [random.uniform(0, MAX_SCORE) for _ in range(BATCH_SIZE)],\n",
                "            dtype=torch.float32,\n",
                "        ),\n",
                "        \"verified\": torch.tensor(\n",
                "            [i != BATCH_SIZE - 1 for i in range(BATCH_SIZE)], dtype=torch.bool\n",
                "        ),\n",
                "        \"proof_size\": torch.tensor(\n",
                "            [random.randint(0, 10000) for _ in range(BATCH_SIZE)], dtype=torch.uint64\n",
                "        ),\n",
                "        \"response_time\": torch.tensor(\n",
                "            [\n",
                "                random.uniform(MIN_RESPONSE_TIME, MAX_RESPONSE_TIME + 2)\n",
                "                for _ in range(BATCH_SIZE)\n",
                "            ],\n",
                "            dtype=torch.float32,\n",
                "        ),\n",
                "        \"maximum_response_time\": torch.full(\n",
                "            (BATCH_SIZE,), MAX_RESPONSE_TIME, dtype=torch.float32\n",
                "        ),\n",
                "        \"minimum_response_time\": torch.full(\n",
                "            (BATCH_SIZE,), MIN_RESPONSE_TIME, dtype=torch.float32\n",
                "        ),\n",
                "        \"block_number\": torch.tensor(\n",
                "            [random.randint(3000000, 10000000) for _ in range(BATCH_SIZE)],\n",
                "            dtype=torch.uint64,\n",
                "        ),\n",
                "        \"validator_uid\": torch.tensor(\n",
                "            [random.randint(0, 256) for _ in range(BATCH_SIZE)], dtype=torch.uint16\n",
                "        ),\n",
                "        \"miner_uid\": torch.tensor(\n",
                "            [random.randint(0, 256) for _ in range(BATCH_SIZE)], dtype=torch.uint16\n",
                "        ),\n",
                "    }\n",
                "    log(\n",
                "        f\"Generated sample inputs. Shape of 'maximum_score': {inputs['maximum_score'].shape}\"\n",
                "    )\n",
                "    return inputs\n",
                "\n",
                "\n",
                "def run_iterations(\n",
                "    num_iterations: int, initial_inputs: Dict[str, torch.Tensor]\n",
                ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
                "    sample_inputs = initial_inputs.copy()\n",
                "    original_response_times = sample_inputs[\"response_time\"].clone()\n",
                "    original_verified = sample_inputs[\"verified\"].clone()\n",
                "\n",
                "    scores_pow = [sample_inputs[\"previous_score\"].clone()]\n",
                "    scores_torch = [sample_inputs[\"previous_score\"].clone()]\n",
                "    reward_model = Reward()\n",
                "\n",
                "    for i in range(num_iterations):\n",
                "        log(f\"Running iteration {i+1}/{num_iterations}\")\n",
                "        if FIX_TIMES_AFTER_INTERVAL:\n",
                "            if i == num_iterations // 3:\n",
                "                sample_inputs[\"response_time\"] = torch.full(\n",
                "                    (BATCH_SIZE,), 4.0, dtype=torch.float32\n",
                "                )\n",
                "            elif i == 2 * num_iterations // 3:\n",
                "                sample_inputs[\"response_time\"] = torch.full(\n",
                "                    (BATCH_SIZE,), 10.0, dtype=torch.float32\n",
                "                )\n",
                "\n",
                "        new_scores_pow = run_inference_via_proof_system(sample_inputs)\n",
                "        new_scores_torch = reward_model(**sample_inputs)[0]\n",
                "\n",
                "        scores_pow.append(new_scores_pow)\n",
                "        scores_torch.append(new_scores_torch)\n",
                "\n",
                "        sample_inputs[\"previous_score\"] = new_scores_pow.clone()\n",
                "        log(\n",
                "            f\"Updated previous_score for next iteration: {sample_inputs['previous_score'][:5]}...\"\n",
                "        )\n",
                "\n",
                "    log(\n",
                "        f\"Completed {num_iterations} iterations. Final scores shape: {scores_pow[-1].shape}\"\n",
                "    )\n",
                "    return (\n",
                "        torch.stack(scores_pow),\n",
                "        torch.stack(scores_torch),\n",
                "        original_response_times,\n",
                "        original_verified,\n",
                "    )\n",
                "\n",
                "\n",
                "def plot_scores_over_time(\n",
                "    scores_over_time_pow: torch.Tensor,\n",
                "    scores_over_time_torch: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                ") -> None:\n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
                "\n",
                "    norm = plt.Normalize(vmin=MIN_RESPONSE_TIME, vmax=MAX_RESPONSE_TIME)\n",
                "    cmap = plt.get_cmap(\"plasma\")\n",
                "\n",
                "    for i in range(BATCH_SIZE):\n",
                "        color = cmap(norm(response_times[i].item()))\n",
                "        ax1.plot(\n",
                "            range(PLOT_INTERVALS + 1),\n",
                "            scores_over_time_pow[:, i],\n",
                "            color=color,\n",
                "            alpha=0.5,\n",
                "        )\n",
                "    sm1 = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
                "    sm1.set_array([])\n",
                "    fig.colorbar(sm1, ax=ax1, label=\"Response Time\")\n",
                "    ax1.set_xlabel(\"Iteration\")\n",
                "    ax1.set_ylabel(\"Score\")\n",
                "    ax1.set_title(\"Change in Scores Over Iterations (PoW)\")\n",
                "\n",
                "    for i in range(BATCH_SIZE):\n",
                "        color = cmap(norm(response_times[i].item()))\n",
                "        ax2.plot(\n",
                "            range(PLOT_INTERVALS + 1),\n",
                "            scores_over_time_torch[:, i],\n",
                "            color=color,\n",
                "            alpha=0.5,\n",
                "        )\n",
                "    sm2 = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
                "    sm2.set_array([])\n",
                "    fig.colorbar(sm2, ax=ax2, label=\"Response Time\")\n",
                "    ax2.set_xlabel(\"Iteration\")\n",
                "    ax2.set_ylabel(\"Score\")\n",
                "    ax2.set_title(\"Change in Scores Over Iterations (Torch)\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def plot_scores_vs_response_times_with_loss(\n",
                "    final_scores_pow: torch.Tensor,\n",
                "    final_scores_torch: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                "    verified: torch.Tensor,\n",
                "    loss: torch.Tensor,\n",
                ") -> None:\n",
                "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 6))\n",
                "\n",
                "    sorted_indices = torch.argsort(response_times, descending=True)\n",
                "    sorted_response_times = response_times[sorted_indices]\n",
                "    sorted_scores_pow = final_scores_pow[sorted_indices]\n",
                "    sorted_scores_torch = final_scores_torch[sorted_indices]\n",
                "    sorted_verified = verified[sorted_indices]\n",
                "\n",
                "    scatter_pow = ax1.scatter(\n",
                "        sorted_response_times[sorted_verified],\n",
                "        sorted_scores_pow[sorted_verified],\n",
                "        c=sorted_response_times[sorted_verified],\n",
                "        cmap=\"plasma\",\n",
                "        label=\"Verified (PoW)\",\n",
                "    )\n",
                "    ax1.scatter(\n",
                "        sorted_response_times[~sorted_verified],\n",
                "        sorted_scores_pow[~sorted_verified],\n",
                "        c=\"red\",\n",
                "        label=\"Non-Verified (PoW)\",\n",
                "    )\n",
                "    fig.colorbar(scatter_pow, ax=ax1, label=\"Response Time\")\n",
                "    ax1.set_xlabel(\"Response Time\")\n",
                "    ax1.set_ylabel(\"Final Score\")\n",
                "    ax1.set_title(\"Final Scores vs Response Times (PoW)\")\n",
                "    ax1.legend()\n",
                "    ax1.invert_xaxis()\n",
                "\n",
                "    scatter_torch = ax2.scatter(\n",
                "        sorted_response_times[sorted_verified],\n",
                "        sorted_scores_torch[sorted_verified],\n",
                "        c=sorted_response_times[sorted_verified],\n",
                "        cmap=\"plasma\",\n",
                "        label=\"Verified (Torch)\",\n",
                "    )\n",
                "    ax2.scatter(\n",
                "        sorted_response_times[~sorted_verified],\n",
                "        sorted_scores_torch[~sorted_verified],\n",
                "        c=\"red\",\n",
                "        label=\"Non-Verified (Torch)\",\n",
                "    )\n",
                "    fig.colorbar(scatter_torch, ax=ax2, label=\"Response Time\")\n",
                "    ax2.set_xlabel(\"Response Time\")\n",
                "    ax2.set_ylabel(\"Final Score\")\n",
                "    ax2.set_title(\"Final Scores vs Response Times (Torch)\")\n",
                "    ax2.legend()\n",
                "    ax2.invert_xaxis()\n",
                "\n",
                "    ax3.plot(range(len(loss)), loss.numpy())\n",
                "    ax3.set_xlabel(\"Iteration\")\n",
                "    ax3.set_ylabel(\"Mean Squared Error\")\n",
                "    ax3.set_title(\"Loss between Torch and PoW\")\n",
                "\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "    log(f\"PoW - Sorted final scores sample: {sorted_scores_pow[:5]}...\")\n",
                "    log(f\"PoW - Sorted response times sample: {sorted_response_times[:5]}...\")\n",
                "    log(f\"PoW - Sorted verified status sample: {sorted_verified[:5]}...\")\n",
                "    log(f\"Torch - Sorted final scores sample: {sorted_scores_torch[:5]}...\")\n",
                "    log(f\"Torch - Sorted response times sample: {sorted_response_times[:5]}...\")\n",
                "    log(f\"Torch - Sorted verified status sample: {sorted_verified[:5]}...\")\n",
                "\n",
                "\n",
                "def process_weights(\n",
                "    scores: torch.Tensor, uids: torch.Tensor, netuid: int, subtensor: bt.subtensor\n",
                ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
                "    return bt.utils.weight_utils.process_weights_for_netuid(\n",
                "        uids=uids, weights=scores, netuid=netuid, subtensor=subtensor\n",
                "    )\n",
                "\n",
                "\n",
                "def plot_processed_weights(\n",
                "    processed_uids: torch.Tensor,\n",
                "    processed_weights: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                "    verified: torch.Tensor,\n",
                "    title: str,\n",
                ") -> None:\n",
                "    sorted_indices = torch.argsort(response_times, descending=True)\n",
                "    sorted_uids = processed_uids[sorted_indices]\n",
                "    sorted_weights = processed_weights[sorted_indices]\n",
                "    sorted_response_times = response_times[sorted_indices]\n",
                "    sorted_verified = verified[sorted_indices]\n",
                "\n",
                "    plt.figure(figsize=(12, 6))\n",
                "    scatter = plt.scatter(\n",
                "        sorted_response_times.numpy(),\n",
                "        sorted_weights.numpy(),\n",
                "        c=sorted_response_times.numpy(),\n",
                "        cmap=\"plasma\",\n",
                "        s=50,\n",
                "        alpha=0.7,\n",
                "    )\n",
                "\n",
                "    plt.scatter(\n",
                "        sorted_response_times[~sorted_verified].numpy(),\n",
                "        sorted_weights[~sorted_verified].numpy(),\n",
                "        facecolors=\"none\",\n",
                "        edgecolors=\"red\",\n",
                "        s=100,\n",
                "        linewidths=2,\n",
                "    )\n",
                "\n",
                "    plt.colorbar(scatter, label=\"Response Time\")\n",
                "    plt.xlabel(\"Response Time\")\n",
                "    plt.ylabel(\"Processed Weight\")\n",
                "    plt.title(title)\n",
                "    plt.gca().invert_xaxis()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def plot_processed_weights_grid(\n",
                "    processed_uids: torch.Tensor,\n",
                "    processed_weights: torch.Tensor,\n",
                "    response_times: torch.Tensor,\n",
                "    verified: torch.Tensor,\n",
                "    title: str,\n",
                ") -> None:\n",
                "    num_charts = BATCH_SIZE // 256\n",
                "    rows = int(np.ceil(np.sqrt(num_charts)))\n",
                "    cols = int(np.ceil(num_charts / rows))\n",
                "\n",
                "    fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
                "    fig.suptitle(title, fontsize=16)\n",
                "\n",
                "    for i in range(num_charts):\n",
                "        ax = axes[i // cols, i % cols] if num_charts > 1 else axes\n",
                "        start_idx = i * 256\n",
                "        end_idx = (i + 1) * 256\n",
                "\n",
                "        chunk_uids = processed_uids[start_idx:end_idx]\n",
                "        chunk_weights = processed_weights[start_idx:end_idx]\n",
                "        chunk_response_times = response_times[start_idx:end_idx]\n",
                "        chunk_verified = verified[start_idx:end_idx]\n",
                "        sorted_indices = torch.argsort(chunk_response_times, descending=True)\n",
                "        sorted_uids = chunk_uids[sorted_indices]\n",
                "        sorted_weights = chunk_weights[sorted_indices]\n",
                "        sorted_response_times = chunk_response_times[sorted_indices]\n",
                "        sorted_verified = chunk_verified[sorted_indices]\n",
                "\n",
                "        scatter = ax.scatter(\n",
                "            sorted_response_times.numpy(),\n",
                "            sorted_weights.numpy(),\n",
                "            c=sorted_response_times.numpy(),\n",
                "            cmap=\"plasma\",\n",
                "            s=20,\n",
                "            alpha=0.7,\n",
                "        )\n",
                "\n",
                "        ax.scatter(\n",
                "            sorted_response_times[~sorted_verified].numpy(),\n",
                "            sorted_weights[~sorted_verified].numpy(),\n",
                "            facecolors=\"none\",\n",
                "            edgecolors=\"red\",\n",
                "            s=40,\n",
                "            linewidths=1,\n",
                "        )\n",
                "\n",
                "        ax.set_xlabel(\"Response Time\")\n",
                "        ax.set_ylabel(\"Processed Weight\")\n",
                "        ax.set_title(f\"Chunk {i+1}\")\n",
                "\n",
                "        ax.invert_xaxis()\n",
                "\n",
                "    for i in range(num_charts, rows * cols):\n",
                "        fig.delaxes(axes.flatten()[i])\n",
                "\n",
                "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def main() -> None:\n",
                "    initial_inputs = generate_sample_inputs()\n",
                "    scores_over_time_pow, scores_over_time_torch, response_times, verified = (\n",
                "        run_iterations(PLOT_INTERVALS, initial_inputs)\n",
                "    )\n",
                "    plot_scores_over_time(scores_over_time_pow, scores_over_time_torch, response_times)\n",
                "\n",
                "    loss = torch.mean((scores_over_time_torch - scores_over_time_pow) ** 2, dim=1)\n",
                "\n",
                "    final_scores_pow = scores_over_time_pow[-1]\n",
                "    final_scores_torch = scores_over_time_torch[-1]\n",
                "\n",
                "    sorted_indices = torch.argsort(response_times, descending=True)\n",
                "    sorted_final_scores_pow = final_scores_pow[sorted_indices]\n",
                "    sorted_final_scores_torch = final_scores_torch[sorted_indices]\n",
                "    sorted_response_times = response_times[sorted_indices]\n",
                "    sorted_verified = verified[sorted_indices]\n",
                "\n",
                "    plot_scores_vs_response_times_with_loss(\n",
                "        sorted_final_scores_pow,\n",
                "        sorted_final_scores_torch,\n",
                "        sorted_response_times,\n",
                "        sorted_verified,\n",
                "        loss,\n",
                "    )\n",
                "\n",
                "    uids = torch.arange(len(final_scores_pow))\n",
                "    netuid = 2\n",
                "    subtensor = bt.subtensor()\n",
                "    processed_uids_pow, processed_weights_pow = process_weights(\n",
                "        final_scores_pow, uids, netuid, subtensor\n",
                "    )\n",
                "    plot_processed_weights(\n",
                "        processed_uids_pow,\n",
                "        processed_weights_pow,\n",
                "        response_times,\n",
                "        verified,\n",
                "        \"Processed Weights (PoW)\",\n",
                "    )\n",
                "    plot_processed_weights_grid(\n",
                "        processed_uids_pow,\n",
                "        processed_weights_pow,\n",
                "        response_times,\n",
                "        verified,\n",
                "        \"Processed Weights Grid (PoW)\",\n",
                "    )\n",
                "    processed_uids_torch, processed_weights_torch = process_weights(\n",
                "        final_scores_torch, uids, netuid, subtensor\n",
                "    )\n",
                "    plot_processed_weights(\n",
                "        processed_uids_torch,\n",
                "        processed_weights_torch,\n",
                "        response_times,\n",
                "        verified,\n",
                "        \"Processed Weights (Torch)\",\n",
                "    )\n",
                "    plot_processed_weights_grid(\n",
                "        processed_uids_torch,\n",
                "        processed_weights_torch,\n",
                "        response_times,\n",
                "        verified,\n",
                "        \"Processed Weights Grid (Torch)\",\n",
                "    )\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
