{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An example reward method\n",
    "\"\"\"\n",
    "\n",
    "import bittensor as bt\n",
    "\n",
    "RATE_OF_RECOVERY = 0.2\n",
    "RATE_OF_DECAY = 0.8\n",
    "\n",
    "MINIMUM_SCORE = 0\n",
    "\n",
    "RESPONSE_TIME_WEIGHT = 0.2\n",
    "PROOF_SIZE_WEIGHT = 0.1\n",
    "\n",
    "RESPONSE_TIME_THRESHOLD = 40\n",
    "PROOF_SIZE_THRESHOLD = 30000\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Reward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Reward, self).__init__()\n",
    "        self.rate_of_decay = RATE_OF_DECAY\n",
    "        self.rate_of_recovery = RATE_OF_RECOVERY\n",
    "        self.minimum_score = MINIMUM_SCORE\n",
    "\n",
    "    def forward(self, max_score, score, verification_result, factor):\n",
    "        \"\"\"\n",
    "        This method calculates the reward for a miner based on the provided score, verification_result, and factor using a neural network module.\n",
    "        Positional Arguments:\n",
    "            max_score (Tensor): The maximum score for the miner.\n",
    "            score (Tensor): The current score for the miner.\n",
    "            verification_result (Tensor): Whether the response that the miner submitted was valid. (1 or 0)\n",
    "            factor (Tensor): The factor to apply to the reward, in case the miner is using multiple hotkeys or serving from the same IP multiple times.\n",
    "        Returns:\n",
    "            Tensor: The new score for the miner.\n",
    "        \"\"\"\n",
    "        # Use 'verification_result' to switch between recovery and decay rates\n",
    "        rate = (\n",
    "            self.rate_of_decay * (1 - verification_result)\n",
    "            + self.rate_of_recovery * verification_result\n",
    "        )\n",
    "\n",
    "        # Calculate distance based on 'verification_result'\n",
    "        distance = (max_score - score) * verification_result + (\n",
    "            score - self.minimum_score\n",
    "        ) * (1 - verification_result)\n",
    "\n",
    "        # Apply factor\n",
    "        new_score = score + rate * distance * factor\n",
    "\n",
    "        return new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "calibration failed max lookup input (0, 1760936591360) is too large\n",
      "calibration failed max lookup input (0, 14070312861696) is too large\n",
      "calibration failed max lookup input (0, 112562502893568) is too large\n",
      "calibration failed max lookup input (0, 28140625723392) is too large\n",
      "calibration failed max lookup input (0, 225125005787136) is too large\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "calibration failed max lookup input (0, 450250011574272) is too large\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+----------------+----------------+---------------------+--------------------+------------------------+\n",
      "| mean_error     | median_error   | max_error      | min_error      | mean_abs_error | median_abs_error | max_abs_error  | min_abs_error  | mean_squared_error  | mean_percent_error | mean_abs_percent_error |\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+----------------+----------------+---------------------+--------------------+------------------------+\n",
      "| 0.000024437904 | 0.000024437904 | 0.000024437904 | 0.000024437904 | 0.000024437904 | 0.000024437904   | 0.000024437904 | 0.000024437904 | 0.00000000059721117 | 0.00004072984      | 0.00004072984          |\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+----------------+----------------+---------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Convert the reward method into a zk circuit by exporting to ONNX and then passing through EZKL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Importing necessary libraries\n",
    "import bittensor as bt\n",
    "import ezkl\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "\n",
    "\n",
    "if os.getcwd().split(\"/\")[-1] != \"model\":\n",
    "    os.chdir(\"./model\")\n",
    "\n",
    "\n",
    "# Instantiate the Reward model and set it to evaluation mode\n",
    "reward_model = Reward()\n",
    "reward_model.eval()\n",
    "bt.logging.trace(\n",
    "    f\"Instantiated Reward model: {reward_model} and set it to evaluation mode.\"\n",
    ")\n",
    "\n",
    "# Define dummy inputs for the model export\n",
    "dummy_inputs = {\n",
    "    \"max_score\": torch.tensor([1.0], dtype=torch.float32),\n",
    "    \"score\": torch.tensor([0.5], dtype=torch.float32),\n",
    "    \"verification_result\": torch.tensor([1.0], dtype=torch.float32),\n",
    "    \"factor\": torch.tensor([1.0], dtype=torch.float32),\n",
    "}\n",
    "bt.logging.trace(f\"Defined dummy inputs for the model export: {dummy_inputs}.\")\n",
    "\n",
    "bt.logging.info(\"Creating zk circuit for the reward function\")\n",
    "# Exporting the model to ONNX format\n",
    "bt.logging.trace(\"Starting the export of the model to ONNX format.\")\n",
    "torch.onnx.export(\n",
    "    reward_model,\n",
    "    tuple(dummy_inputs.values()),\n",
    "    \"network.onnx\",\n",
    "    opset_version=11,\n",
    "    input_names=list(dummy_inputs.keys()),\n",
    "    output_names=[\"output\"],\n",
    ")\n",
    "bt.logging.trace(\"Completed exporting the model to ONNX format: network.onnx.\")\n",
    "# Running inference with ONNX Runtime\n",
    "bt.logging.trace(\"Initiating inference with ONNX Runtime on network.onnx.\")\n",
    "ort_session = ort.InferenceSession(\"network.onnx\")\n",
    "np_inputs = {k: np.array(v, dtype=np.float32) for k, v in dummy_inputs.items()}\n",
    "output = ort_session.run(\n",
    "    output_names=[\"output\"],\n",
    "    input_feed=np_inputs,\n",
    ")\n",
    "bt.logging.trace(f\"Completed inference with ONNX Runtime. Output: {output}.\")\n",
    "# Saving input and output data to JSON file\n",
    "bt.logging.trace(\"Saving the input and output data to a JSON file: input.json.\")\n",
    "with open(\"input.json\", \"w\", encoding=\"utf8\") as input_file:\n",
    "    input_json_object = {\n",
    "        \"input_data\": [v.tolist() for v in dummy_inputs.values()],\n",
    "        \"output_data\": [output[0].tolist()],\n",
    "    }\n",
    "    json_str = json.dumps(input_json_object, indent=4)\n",
    "    input_file.write(json_str)\n",
    "bt.logging.trace(\n",
    "    \"Saved the input and output data to a JSON file successfully: input.json.\"\n",
    ")\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"fixed\"\n",
    "ezkl.gen_settings(py_run_args=py_run_args)\n",
    "ezkl.calibrate_settings(\"input.json\", target=\"accuracy\")\n",
    "ezkl.compile_circuit()\n",
    "ezkl.get_srs()\n",
    "ezkl.setup(\n",
    "    model=\"model.compiled\", vk_path=\"vk.key\", pk_path=\"pk.key\", srs_path=\"kzg.srs\"\n",
    ")\n",
    "ezkl.gen_witness(\n",
    "    data=\"input.json\",\n",
    "    model=\"model.compiled\",\n",
    "    output=\"witness.json\",\n",
    "    vk_path=\"vk.key\",\n",
    "    srs_path=\"kzg.srs\",\n",
    ")\n",
    "ezkl.prove(witness=\"witness.json\", model=\"model.compiled\", proof_path=\"proof.json\")\n",
    "ezkl.verify(vk_path=\"vk.key\", proof_path=\"proof.json\")\n",
    "bt.logging.success(\"Successfully circuitized the reward function.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resulting score in hex (decimal):  0000000000ae1785010000000000000000000000000000000000000000000000 (0.7599462866783142)\n",
      "Attempting to verify with good instances and proof\n",
      "Verified\n",
      "Attempting to verify modified instances\n",
      "Not Verified\n",
      "Attempting to verify a modified proof\n",
      "Not Verified\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conduct example proven reward calculations\n",
    "\"\"\"\n",
    "import copy\n",
    "# Setup example input\n",
    "input = [[1.0], [0.7], [1.0], [1.0]]\n",
    "\n",
    "# Copy into the input.json file\n",
    "with open(\"input.json\", \"w\", encoding=\"utf8\") as input_file:\n",
    "    input_json_object = {\n",
    "        \"input_data\": input,\n",
    "    }\n",
    "    json_str = json.dumps(input_json_object, indent=4)\n",
    "    input_file.write(json_str)\n",
    "\n",
    "# Generate a witness.json file\n",
    "ezkl.gen_witness(data=\"input.json\", model=\"model.compiled\", output=\"witness.json\")\n",
    "# Generate a proof\n",
    "ezkl.prove(witness=\"witness.json\", model=\"model.compiled\", proof_path=\"proof.json\")\n",
    "\n",
    "with open(\"proof.json\", \"r\", encoding=\"utf8\") as proof_file:\n",
    "    proof_data = json.load(proof_file)\n",
    "\n",
    "\n",
    "print(\"Resulting score in hex (decimal): \", proof_data[\"instances\"][0][-1],  \"(\" + proof_data[\"pretty_public_inputs\"][\"rescaled_outputs\"][0][0] + \")\")\n",
    "\n",
    "print(\"Attempting to verify with good instances and proof\")\n",
    "\n",
    "# Verify\n",
    "\n",
    "try:\n",
    "    ezkl.verify()\n",
    "    print(\"Verified\")\n",
    "except:\n",
    "    print(\"Not verified\")\n",
    "\n",
    "# Modify\n",
    "\n",
    "print(\"Attempting to verify modified instances\")\n",
    "\n",
    "with open(\"proof.json\", \"w\", encoding=\"utf8\") as proof_file:\n",
    "    # Modify one of the instances\n",
    "    modified_instances_proof_data = copy.deepcopy(proof_data)\n",
    "    modified_instances_proof_data[\"instances\"][0][-1] = modified_instances_proof_data[\"instances\"][0][-1].replace(\"5\", \"6\")\n",
    "    json_str = json.dumps(modified_instances_proof_data, indent=4)\n",
    "    proof_file.write(json_str)\n",
    "\n",
    "try:\n",
    "    ezkl.verify()\n",
    "    print(\"Verified\")\n",
    "except:\n",
    "    print(\"Not Verified\")\n",
    "\n",
    "print(\"Attempting to verify a modified proof\")\n",
    "\n",
    "with open(\"proof.json\", \"w\", encoding=\"utf8\") as proof_file:\n",
    "    # Modify one of the instances\n",
    "    modified_proof_data = copy.deepcopy(proof_data)\n",
    "    modified_proof_data[\"proof\"][0] = modified_proof_data[\"proof\"][1]\n",
    "    json_str = json.dumps(modified_proof_data, indent=4)\n",
    "    proof_file.write(json_str)\n",
    "\n",
    "try:\n",
    "    ezkl.verify()\n",
    "    print(\"Verified\")\n",
    "except:\n",
    "    print(\"Not Verified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurons--Me-GsZC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
