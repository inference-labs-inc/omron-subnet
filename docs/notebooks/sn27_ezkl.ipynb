{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import bittensor as bt\n",
    "\n",
    "pow_timeout = 30\n",
    "pow_min_difficulty = 7\n",
    "pow_max_difficulty = 12\n",
    "\n",
    "success_weight = 1\n",
    "difficulty_weight = 1\n",
    "time_elapsed_weight = 0.3\n",
    "failed_penalty_weight = 0.4\n",
    "allocation_weight = 0.21\n",
    "\n",
    "max_score_challenge = 100 * (success_weight + difficulty_weight + time_elapsed_weight)\n",
    "max_score = max_score_challenge + 100 * allocation_weight\n",
    "\n",
    "failed_penalty_exp = 1.5\n",
    "\n",
    "# Define the stock python reward function\n",
    "\n",
    "def normalize(val, min_value, max_value):\n",
    "    return (val - min_value) / (max_value - min_value)\n",
    "\n",
    "\n",
    "def prevent_none(val):\n",
    "    return 0 if not val else val\n",
    "\n",
    "\n",
    "def percent(a, b):\n",
    "    if b == 0:\n",
    "        return 0\n",
    "    return (a / b) * 100\n",
    "\n",
    "\n",
    "def percent_yield(a, b):\n",
    "    if a == 0:\n",
    "        return 100\n",
    "    return ((b - a) / b) * 100\n",
    "\n",
    "\n",
    "def calc_score(\n",
    "    response,\n",
    "    hotkey,\n",
    "    allocated_hotkeys,\n",
    "    penalized_hotkeys,\n",
    "    validator_hotkeys,\n",
    "    jolt_params,\n",
    "    i\n",
    "):\n",
    "    try:\n",
    "        challenge_attempts = prevent_none(response.get(\"challenge_attempts\", 1))\n",
    "        challenge_successes = prevent_none(response.get(\"challenge_successes\", 0))\n",
    "        last_20_challenge_failed = prevent_none(\n",
    "            response.get(\"last_20_challenge_failed\", 0)\n",
    "        )\n",
    "        challenge_elapsed_time_avg = prevent_none(\n",
    "            response.get(\"challenge_elapsed_time_avg\", pow_timeout)\n",
    "        )\n",
    "        challenge_difficulty_avg = prevent_none(\n",
    "            response.get(\"challenge_difficulty_avg\", pow_min_difficulty)\n",
    "        )\n",
    "        has_docker = response.get(\"has_docker\", False)\n",
    "\n",
    "        assert challenge_attempts == jolt_params[\"challenge_attempts\"][i], f\"challenge_attempts: {challenge_attempts} != {jolt_params['challenge_attempts'][i]}\"\n",
    "        assert challenge_successes == jolt_params[\"challenge_successes\"][i], f\"challenge_successes: {challenge_successes} != {jolt_params['challenge_successes'][i]}\"\n",
    "        assert last_20_challenge_failed == jolt_params[\"last_20_challenge_failed\"][i], f\"last_20_challenge_failed: {last_20_challenge_failed} != {jolt_params['last_20_challenge_failed'][i]}\"\n",
    "        assert challenge_elapsed_time_avg == jolt_params[\"challenge_elapsed_time_avg\"][i], f\"challenge_elapsed_time_avg: {challenge_elapsed_time_avg} != {jolt_params['challenge_elapsed_time_avg'][i]}\"\n",
    "        assert challenge_difficulty_avg == jolt_params[\"challenge_difficulty_avg\"][i], f\"challenge_difficulty_avg: {challenge_difficulty_avg} != {jolt_params['challenge_difficulty_avg'][i]}\"\n",
    "        assert has_docker == jolt_params[\"has_docker\"][i], f\"has_docker: {has_docker} != {jolt_params['has_docker'][i]}\"\n",
    "\n",
    "        difficulty_val = max(\n",
    "            min(challenge_difficulty_avg, pow_max_difficulty),\n",
    "            pow_min_difficulty,\n",
    "        )\n",
    "        difficulty_modifier = percent(difficulty_val, pow_max_difficulty)\n",
    "\n",
    "        difficulty = difficulty_modifier * difficulty_weight\n",
    "        successes_ratio = percent(challenge_successes, challenge_attempts)\n",
    "        successes = successes_ratio * success_weight\n",
    "\n",
    "        time_elapsed_modifier = percent_yield(\n",
    "            challenge_elapsed_time_avg, pow_timeout\n",
    "        )\n",
    "        time_elapsed = time_elapsed_modifier * time_elapsed_weight\n",
    "\n",
    "        last_20_challenge_failed_modifier = percent(\n",
    "            last_20_challenge_failed, 20\n",
    "        )\n",
    "        failed_penalty = (\n",
    "            failed_penalty_weight\n",
    "            * (last_20_challenge_failed_modifier / 100) ** failed_penalty_exp\n",
    "            * 100\n",
    "        )\n",
    "\n",
    "        allocation_score = difficulty_modifier * allocation_weight\n",
    "        allocation_status = hotkey in allocated_hotkeys\n",
    "\n",
    "        assert max_score_challenge == 100 * (\n",
    "            success_weight + difficulty_weight + time_elapsed_weight\n",
    "        )\n",
    "        max_score_allocation = 100 * allocation_weight\n",
    "        assert max_score == max_score_challenge + max_score_allocation\n",
    "        final_score = difficulty + successes + time_elapsed - failed_penalty\n",
    "\n",
    "        penalty = not (has_docker)\n",
    "\n",
    "        if allocation_status:\n",
    "            final_score = (\n",
    "                max_score_challenge * (1 - allocation_weight) + allocation_score\n",
    "            )\n",
    "        else:\n",
    "            final_score = difficulty + successes + time_elapsed - failed_penalty\n",
    "            if penalty:\n",
    "                final_score = final_score / 2\n",
    "\n",
    "        if (\n",
    "            last_20_challenge_failed >= 19 or challenge_successes == 0\n",
    "        ) and not allocation_status:\n",
    "            print(\"Returning 0 due to high failure rate or no successes\")\n",
    "            return 0\n",
    "\n",
    "        if hotkey in penalized_hotkeys:\n",
    "            penalty_count = penalized_hotkeys.count(hotkey)\n",
    "            half_validators = len(validator_hotkeys) / 2\n",
    "            assert half_validators == jolt_params[\"half_validators\"], f\"half_validators: {half_validators} != {jolt_params['half_validators']}\"\n",
    "\n",
    "            if penalty_count >= half_validators:\n",
    "                final_score = 0\n",
    "            else:\n",
    "                penalty_multiplier = max(1 - (penalty_count / half_validators), 0)\n",
    "                final_score *= penalty_multiplier\n",
    "\n",
    "        final_score = max(0, final_score)\n",
    "\n",
    "        normalized_score = normalize(final_score, 0, max_score)\n",
    "\n",
    "        return normalized_score\n",
    "    except Exception as e:\n",
    "        bt.logging.error(\n",
    "            f\"An error occurred while calculating score for the following hotkey - {hotkey}: {e}\"\n",
    "        )\n",
    "        return 0\n",
    "\n",
    "\n",
    "runtimes = [0]\n",
    "time_now = time.time()\n",
    "existing_dir = os.getcwd()\n",
    "os.chdir(\n",
    "    \"../../neurons/deployment_layer/model_1d60d545b7c5123fd60524dcbaf57081ca7dc4a9ec36c892927a3153328d17c0\"\n",
    ")\n",
    "subprocess.run([\"cargo\", \"build\", \"--release\"], check=True)\n",
    "runtimes.append(time.time() - time_now)\n",
    "time_now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import random\n",
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def generate_test_data(batch_size: int):\n",
    "    # Generate random test data tensors\n",
    "    def generate_tensor(min_val, max_val, batch_size):\n",
    "        return torch.tensor(\n",
    "            [[float(rand.randint(min_val, max_val))] for _ in range(batch_size)]\n",
    "        )\n",
    "\n",
    "    def generate_random_tensor(min_val, max_val, batch_size):\n",
    "        return torch.tensor(\n",
    "            [[min_val + rand.random() * (max_val - min_val)] for _ in range(batch_size)]\n",
    "        )\n",
    "\n",
    "    def generate_uid_tensor(batch_size, prob=0.1):\n",
    "        return torch.tensor(\n",
    "            [\n",
    "                [rand.randint(0, 256) if rand.random() < prob else 0]\n",
    "                for _ in range(batch_size)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    challenge_attempts = generate_tensor(5, 10, batch_size)\n",
    "    challenge_successes = generate_tensor(4, 8, batch_size)\n",
    "    last_20_challenge_failed = generate_tensor(0, 3, batch_size)\n",
    "    challenge_elapsed_time_avg = generate_random_tensor(4.0, 8.0, batch_size)\n",
    "    last_20_difficulty_avg = generate_random_tensor(1.5, 2.5, batch_size)\n",
    "    has_docker = torch.tensor([[True] for _ in range(batch_size)])\n",
    "    uid = generate_tensor(0, 256, batch_size)\n",
    "    allocated_uids = generate_uid_tensor(batch_size)\n",
    "    penalized_uids = generate_uid_tensor(batch_size)\n",
    "    validator_uids = generate_uid_tensor(batch_size)\n",
    "\n",
    "    return {\n",
    "        \"challenge_attempts\": challenge_attempts,\n",
    "        \"challenge_successes\": challenge_successes,\n",
    "        \"last_20_challenge_failed\": last_20_challenge_failed,\n",
    "        \"challenge_elapsed_time_avg\": challenge_elapsed_time_avg,\n",
    "        \"last_20_difficulty_avg\": last_20_difficulty_avg,\n",
    "        \"has_docker\": has_docker,\n",
    "        \"uid\": uid,\n",
    "        \"allocated_uids\": allocated_uids,\n",
    "        \"penalized_uids\": penalized_uids,\n",
    "        \"validator_uids\": validator_uids\n",
    "    }\n",
    "\n",
    "def compare_scores(circuit_scores: torch.Tensor, jolt_scores: List[float]) -> None:\n",
    "    table = Table(title=\"Score Comparison\")\n",
    "    table.add_column(\"UID\", justify=\"right\", style=\"cyan\")\n",
    "    table.add_column(\"Circuit Score\", justify=\"right\", style=\"magenta\")\n",
    "    table.add_column(\"Jolt Score\", justify=\"right\", style=\"green\")\n",
    "    table.add_column(\"Difference\", justify=\"right\", style=\"red\")\n",
    "\n",
    "    red_diff_count = 0\n",
    "    total_diff = 0.0\n",
    "\n",
    "    for i, (circ, jolt) in enumerate(zip(circuit_scores, jolt_scores)):\n",
    "        diff = abs(float(circ) - float(jolt))\n",
    "        total_diff += diff\n",
    "        diff_color = \"red\" if diff > 1e-6 else \"green\"\n",
    "        red_diff_count += diff_color == \"red\"\n",
    "\n",
    "        table.add_row(\n",
    "            f\"{i}\",\n",
    "            f\"{float(circ):.6f}\",\n",
    "            f\"{float(jolt):.6f}\",\n",
    "            f\"[{diff_color}]{diff:+.6f}[/{diff_color}]\"\n",
    "        )\n",
    "\n",
    "    total_count = len(circuit_scores)\n",
    "    red_percentage = (red_diff_count / total_count) * 100\n",
    "    avg_diff = total_diff / total_count\n",
    "\n",
    "    table.add_row(\"\", \"\", \"\", \"\")\n",
    "    table.add_row(\"\", \"\", \"High Loss %:\", f\"[red]{red_percentage:.2f}%[/red]\")\n",
    "    table.add_row(\"\", \"\", \"Avg Difference:\", f\"[yellow]{avg_diff:.6f}[/yellow]\")\n",
    "\n",
    "    console = Console()\n",
    "    console.width = 140\n",
    "    console.print(table)\n",
    "\n",
    "def plot_scores(circuit_scores: torch.Tensor, jolt_scores: List[float]) -> None:\n",
    "    def sort_and_unzip(scores):\n",
    "        return zip(*sorted(enumerate(scores), key=lambda x: x[1]))\n",
    "\n",
    "    circuit_indices, circuit_sorted = sort_and_unzip([float(x) for x in circuit_scores])\n",
    "    jolt_indices, jolt_sorted = sort_and_unzip(jolt_scores)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    ax1.scatter(range(len(circuit_sorted)), circuit_sorted, alpha=0.6)\n",
    "    ax1.set_title('Circuit Scores (Sorted)')\n",
    "    ax1.set_xlabel('Index (Sorted by Score)')\n",
    "    ax1.set_ylabel('Score')\n",
    "\n",
    "    ax2.scatter(range(len(jolt_sorted)), jolt_sorted, alpha=0.6)\n",
    "    ax2.set_title('Jolt Scores (Sorted)')\n",
    "    ax2.set_xlabel('Index (Sorted by Score)')\n",
    "    ax2.set_ylabel('Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    circuit = Circuit()\n",
    "    test_data = generate_test_data(BATCH_SIZE)\n",
    "\n",
    "    # Run circuit\n",
    "    circuit_scores = circuit(**test_data)\n",
    "\n",
    "    # Run Jolt comparison\n",
    "    with open(\"input.json\", \"r\") as f:\n",
    "        jolt_inputs = json.load(f)\n",
    "\n",
    "    subprocess.run(\n",
    "        [\"cargo\", \"run\", \"--release\", \"prove\", \"--input\", \"input.json\", \"--output\", \"output.json\", \"--proof\", \"proof.bin\"],\n",
    "        check=True\n",
    "    )\n",
    "\n",
    "    with open(\"output.json\", \"r\") as f:\n",
    "        jolt_scores = json.load(f)\n",
    "\n",
    "    compare_scores(circuit_scores, jolt_scores)\n",
    "    plot_scores(circuit_scores, jolt_scores)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
